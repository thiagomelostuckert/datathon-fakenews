{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLD49f40X/kraMAZ8W7Bps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagomelostuckert/datathon-fakenews/blob/main/3_Telegram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estruturação de aplicação para detecção de notícias a partir da extração de mensagens em grupo do Telegram\n",
        "\n",
        "Agora que o modelo já foi treinado é preciso analisar a performance dele em tempo real. Em parceria com um órgão do XX, a fração de D&A recebeu informações sobre um grupo de Telegram em que há suspeita de desinformação. Quando estiver em posse do modelo treinado, a equipe pode buscar representantes do desafio para obter o link do grupo.\n",
        "O engenheiro de dados deverá desenvolver aplicação que acompanha constantemente o grupo designado. Na ocorrência de uma mensagem nesse grupo, a aplicação deverá:\n",
        "\n",
        "i) preprocessar o texto da mesma forma que na etapa 1;\n",
        "\n",
        "ii) carregar os parâmetros do modelo treinado na etapa 2;\n",
        "\n",
        "iii) realizar inferência no texto processado, gerando previsão de se a notícia é falsa ou não;\n",
        "\n",
        "iv) salvar o texto, o timestamp de recebimento da mensagem, o timestamp após a realização da inferência e a previsão do modelo para aquela notícia em um pandas dataframe;\n",
        "\n",
        "v) ao fim do recebimento das mensagens (será indicado ao grupo), deverá salvar o pandas dataframe em formato .csv.\n",
        "\n",
        "Recomenda-se a utilização da biblioteca python telethon, que é assíncrona (deve ser utilizada conjuntamente à biblioteca asyncio). É possível utilizar a biblioteca no Google Colab (nesse caso, deve utilizar ainda o nest_asyncio). Para utilizar a biblioteca telethon é necessário também obter os dados da API do Telegram, que pode ser feito utilizadno esse link (https://core.telegram.org/api/obtaining_api_id).\n",
        "\n",
        "Serão considerados na avaliação: intervalo de tempo entre o recebimento da mensagem e a realização da inferência; eficiência do código."
      ],
      "metadata": {
        "id": "81O01SErqUuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das bibliotecas"
      ],
      "metadata": {
        "id": "2g_O-VvyqRzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Pré-processamento\n",
        "import nltk\n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "G1dmtDvBmT45"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i) preprocessar o texto da mesma forma que na etapa 1;"
      ],
      "metadata": {
        "id": "uTSNMObTmLV4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cazgY0nsmTWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No pré-processamento de linguagem natural é comum retirar palavras sem significado semântico (conhecidas em inglês como \"stop words\")."
      ],
      "metadata": {
        "id": "z3MpvCCrmsNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopwords em português:\n",
        "nltk.download('stopwords')\n",
        "stopwordspt = nltk.corpus.stopwords.words('portuguese')\n",
        "stopwordsen = nltk.corpus.stopwords.words('english')\n",
        "stopwordspt[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKpiJDAvmyfq",
        "outputId": "29c116a0-0e7c-4a26-ee6a-0fd83b5fa709"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'à',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outro pré-processamento possível é a retirada de prefixos e sufixos desnecessários das palavras ( processo conhecido em inglês pelos termos \"lemmatizing and stemming\")"
      ],
      "metadata": {
        "id": "kOJs0gJum1yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download lista de radicais e sufixos\n",
        "!wget https://github.com/michmech/lemmatization-lists/raw/master/lemmatization-pt.txt -q\n",
        "nltk.download('rslp')\n",
        "\n",
        "ptstemmer = RSLPStemmer()\n",
        "enstemmer = WordNetLemmatizer()\n",
        "\n",
        "# Convert to dictionary\n",
        "lmztpt = {}\n",
        "dic = open(\"lemmatization-pt.txt\")\n",
        "for line in dic:\n",
        "  txt = line.split()\n",
        "  lmztpt[txt[1]] = txt[0]\n",
        "\n",
        "# Lemmatize wherever possible\n",
        "def PortugueseMess(word):\n",
        "  if word in lmztpt.keys():\n",
        "    return lmztpt.get(word)\n",
        "  else:\n",
        "    return ptstemmer.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om1_oCONm24w",
        "outputId": "ce66e9b7-6fd4-4c4b-fafc-1d5840639051"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii) carregar os parâmetros do modelo treinado na etapa 2;"
      ],
      "metadata": {
        "id": "GtJ92MV-mSYe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pedBSNhTmcQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii) realizar inferência no texto processado, gerando previsão de se a notícia é falsa ou não;"
      ],
      "metadata": {
        "id": "Tb1CaYf-mYRY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLXXupcxmhuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iv) salvar o texto, o timestamp de recebimento da mensagem, o timestamp após a realização da inferência e a previsão do modelo para aquela notícia em um pandas dataframe;"
      ],
      "metadata": {
        "id": "TfbHFiCJmguv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6KcIf9M-KmkZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "v) ao fim do recebimento das mensagens (será indicado ao grupo), deverá salvar o pandas dataframe em formato .csv."
      ],
      "metadata": {
        "id": "mebAGz5Wmle9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDdc2j9vmOll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}